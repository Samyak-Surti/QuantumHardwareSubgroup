{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unionfind\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### graph data structure\n",
    "class graph:\n",
    "    def __init__(self, vertexlist, edgelist):\n",
    "\n",
    "        self.vertices = vertexlist\n",
    "        self.edges = edgelist\n",
    "        self.neighbors = {v: [] for v in vertexlist}\n",
    "        self.leaves = vertexlist.copy()\n",
    "        for (u,v) in edgelist:\n",
    "            self.neighbors[u].append(v)\n",
    "            self.neighbors[v].append(u)\n",
    "            if len(self.neighbors[u]) > 1:\n",
    "                self.leaves.remove(u)\n",
    "            if len(self.neighbors[v]) > 1:\n",
    "                self.leaves.remove(v)\n",
    "\n",
    "    def incident_edges(self, u):\n",
    "        incident = []\n",
    "        for v in self.vertices:\n",
    "            if (u,v) in self.edges: \n",
    "                incident.append({u,v})\n",
    "        return incident\n",
    "\n",
    "    def find_neighbors(self, u):\n",
    "        neighbors = []\n",
    "        for v in self.vertices:\n",
    "            if (u,v) in self.edges or (v,u) in self.edges: \n",
    "                neighbors.append(v)\n",
    "        return neighbors\n",
    "    \n",
    "    def add_vertex(self, u):\n",
    "        if u not in self.vertices:\n",
    "            self.vertices.append(u)\n",
    "            self.neighbors[u] = []\n",
    "            self.leaves.append(u)\n",
    "            \n",
    "    def add_edge(self, e):\n",
    "        if e not in self.edges:\n",
    "            (u,v) = e\n",
    "            if u not in self.vertices:\n",
    "                self.add_vertex(u)\n",
    "            if v not in self.vertices:\n",
    "                self.add_vertex(v)\n",
    "            self.neighbors[u].append(v)\n",
    "            self.neighbors[v].append(u)\n",
    "            if len(self.neighbors[u]) > 1:\n",
    "                self.leaves.remove(u)\n",
    "            if len(self.neighbors[v]) > 1:\n",
    "                self.leaves.remove(v)\n",
    "            self.edges.append(e)\n",
    "        \n",
    "    def remove_edge(self, e):\n",
    "        (u,v) = e\n",
    "        if len(self.neighbors[u]) <= 1:\n",
    "            self.leaves.remove(u)\n",
    "            self.leaves.append(v)\n",
    "        if len(self.neighbors[v]) <= 1:\n",
    "            self.leaves.remove(v)\n",
    "            self.leaves.append(u)\n",
    "        self.neighbors[u].remove(v)\n",
    "        self.neighbors[v].remove(u)\n",
    "        self.edges.remove(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class edgedict(dict):\n",
    "    def __getitem__(self, key):\n",
    "        if key in self:\n",
    "            return super().__getitem__(key)\n",
    "        return super().__getitem__(tuple(reversed(key)))\n",
    "    def __setitem__(self, key, value):\n",
    "        if tuple(reversed(key)) in self:\n",
    "            return super().__setitem__(tuple(reversed(key)), value)\n",
    "        else: \n",
    "            return super().__setitem__(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Union Find Decoder Part 1 (Construct Modified Erasure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_modified_erasure(decoder_graph, syndrome, erasure):\n",
    "    #1: initialize clusers, support list, boundary lists\n",
    "    clusters = unionfind.UnionFind(decoder_graph.vertices) #I'm assuming the initial erasure is empty here\n",
    "    support = edgedict({e: 1 if e in erasure else 0 for e in decoder_graph.edges})\n",
    "    print(support)\n",
    "    boundaries = {s: [s] for s in decoder_graph.vertices}#{s: decoder_graph.neighbors[s] for s in syndrome}\n",
    "    #2: list all clusters with an odd number of marked vertices\n",
    "    print(clusters.components())\n",
    "    print(list(sum(syndrome[i] for i in v)%2==1 for v in clusters.components()))\n",
    "    L = [clusters[clusters.find(list(v)[0])] for v in clusters.components() if sum(syndrome[i] for i in v) % 2 == 1]\n",
    "    print(L)\n",
    "    #3 while there are odd clusters\n",
    "    while L != []:\n",
    "        #4: initialize empty fusion list\n",
    "        fusion = []\n",
    "        print('current L: ',L)\n",
    "        #5 for all u in L, grow the cluster by half an edge\n",
    "        for u in L:\n",
    "            #grow the cluster\n",
    "            root_u = clusters[clusters.find(u)]\n",
    "            for b in boundaries[root_u]:\n",
    "                for n in decoder_graph.find_neighbors(b):\n",
    "                    #grow each edge from the boundary by 0.5\n",
    "                    if support[(b,n)] < 1:\n",
    "                        support[(b, n)] += 0.5\n",
    "                    #add new edges to fusion list\n",
    "                    if support[(b,n)] == 1:\n",
    "                        fusion.append((b,n))\n",
    "        #6: for all edges in fusion list, union the clusters if needed\n",
    "        print('fusion:', fusion)\n",
    "        for edge in fusion:\n",
    "            u = edge[0]\n",
    "            v = edge[1]\n",
    "            if u not in clusters._elts:\n",
    "                clusters.add(u)\n",
    "                boundaries[u] = [u]\n",
    "            if v not in clusters._elts:\n",
    "                clusters.add(v)\n",
    "                boundaries[v] = [v]\n",
    "            if not clusters.connected(u,v):\n",
    "                #7 for all edges in fusion list, update the boundary lists\n",
    "                #####but didn't we just union the clusters?####\n",
    "                root_u = clusters[clusters.find(u)]\n",
    "                root_v = clusters[clusters.find(v)]\n",
    "                if len(clusters.component(root_u)) > len(clusters.component(root_v)):\n",
    "                #append boundary list of v to boundary list of u\n",
    "                    boundaries[root_u].extend(boundaries[root_v])\n",
    "                    #boundaries[root_u].remove(u)\n",
    "                    #boundaries[root_u].remove(v)\n",
    "                else:\n",
    "                #append boundary list of u to boundary list of v\n",
    "                    boundaries[root_v].extend(boundaries[root_u])\n",
    "                    #boundaries[root_v].remove(u)\n",
    "                    #boundaries[root_v].remove(v)\n",
    "                clusters.union(u,v)\n",
    "            else:\n",
    "                fusion.remove(edge)\n",
    "            print(clusters)\n",
    "\n",
    "        #8 replace each u in L with find(u) (new root)\n",
    "        Lnew = []\n",
    "        for u in L:\n",
    "            u_new = clusters[clusters.find(u)]\n",
    "            print('groups:', clusters.groups)\n",
    "            if u_new not in Lnew:\n",
    "                Lnew.append(u_new)\n",
    "                ####9: remove vertices in boundary list of u that are not boundary vertices\n",
    "                for v in boundaries[u_new]:\n",
    "                    #if all edges have support 1, remove from boundary\n",
    "                    if all(support[tuple(s)]==1 for s in decoder_graph.incident_edges(v)): boundaries[u_new].remove(v)\n",
    "\n",
    "\n",
    "        L = Lnew\n",
    "        #10\n",
    "        if len(clusters.component(u)) % 2 == 0 and u in L:\n",
    "            L.remove(u)\n",
    "    #11\n",
    "    for edge in support.keys():\n",
    "        if support[edge] == 1: #fully-grown edge\n",
    "            erasure.append(edge)\n",
    "    #result at this point is a list of edges making up the modified erasure\n",
    "    return erasure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Union Find Decoder Part 2 (Apply Peeling Decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####12 apply peeling decoder to the erasure\n",
    "def peeling_decoder(erasure, edges_to_qubits, num_qs):\n",
    "    erasure_vertices = set(list(zip(*erasure))[0])\n",
    "    erasure_vertices.update(set(list(zip(*erasure))[1]))\n",
    "    erasure_vertices = list(erasure_vertices)\n",
    "    #1: construct spanning forest of erasure\n",
    "    erasure_forest = graph([],[]) #need vertex list for modified erasure\n",
    "    r = erasure_vertices[0] #pick a root\n",
    "    remaining_vertices = erasure_vertices[1:]\n",
    "    visited = set()\n",
    "    queue = [r]\n",
    "\n",
    "    while remaining_vertices: \n",
    "        #find a connected component\n",
    "        while queue:\n",
    "            u = queue.pop(0)\n",
    "            if remaining_vertices:\n",
    "                erasure_forest.add_vertex(u)\n",
    "                neighbors = decoder_graph.neighbors[u]\n",
    "                for v in neighbors:\n",
    "                    if v not in visited:\n",
    "                        visited.add(u)\n",
    "                        erasure_forest.add_edge({u,v}) #modify add_edge to do this automatically\n",
    "                        queue.append(v)\n",
    "                        if v in remaining_vertices:\n",
    "                            remaining_vertices.remove(v)\n",
    "                            #need to break out of the queue loop if remaining_vertices is empty, possibly by removing from queue?\n",
    "\n",
    "\n",
    "    #2 initialize A\n",
    "    A = []\n",
    "    #3: while the forest is nonempty\n",
    "    while erasure_forest.edges != []:\n",
    "        #pick a leaf and remove e, with pendant vertex u\n",
    "        #get vertices, id pendant vertex\n",
    "        print(erasure_forest.edges)\n",
    "        print(erasure_forest.leaves)\n",
    "        u = erasure_forest.leaves[0]\n",
    "        print(u)\n",
    "        v = erasure_forest.neighbors[u][0]\n",
    "        e = {u,v}\n",
    "        print(e)\n",
    "        erasure_forest.remove_edge(e) #need something that updates the leaves when removing edges\n",
    "        #4: if u is in the syndrome, add e to A, remove u from syndrome, and flip v in syndrome\n",
    "        if syndrome[u]==1:\n",
    "            A.append(edges_to_qubits[(u,v)][0])\n",
    "            syndrome[u]=1\n",
    "            if syndrome[v]==1:\n",
    "                syndrome[v]=0\n",
    "            else:\n",
    "                syndrome[v]=1   \n",
    "        #(otherwise, do nothing)\n",
    "    #return product of Z_e for e in A\n",
    "    P = str()\n",
    "    correction = [0 for i in range(num_qs)]\n",
    "    for e in A:\n",
    "        #qs.append(edges_to_qubits[e])\n",
    "        P += 'Z'+str(e)\n",
    "        correction[e] = 1\n",
    "    print(P)\n",
    "    return correction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_graph = graph([0, 1, 2, 3], [(0, 1), (1, 2), (2, 3), (3, 0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need: 1) decoder graph \n",
    "decoder_graph = graph([0, 1, 2, 3], [(0, 1), (1, 2), (2, 3), (3, 0)])\n",
    "#print(decoder_graph.vertices)\n",
    "#syndrome 2) list of -1 syndrome vertices\n",
    "syndrome = {0:0, 1:0, 2:1, 3:1}\n",
    "#erasure 3) list of erased edges\n",
    "erasure = []\n",
    "#produce modified erasure to apply peeling decoder to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 1): 0, (1, 2): 0, (2, 3): 0, (3, 0): 0}\n",
      "[{0}, {1}, {2}, {3}]\n",
      "[False, False, True, True]\n",
      "[2, 3]\n",
      "current L:  [2, 3]\n",
      "fusion: [(3, 2)]\n",
      "<UnionFind:\n",
      "\telts=[0, 1, 2, 3],\n",
      "\tsiz=[1, 1, 1, 2],\n",
      "\tpar=[0, 1, 3, 3],\n",
      "n_elts=4,n_comps=3>\n",
      "[(2, 3)]\n"
     ]
    }
   ],
   "source": [
    "erasure = construct_modified_erasure(decoder_graph, syndrome, erasure)\n",
    "print(erasure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "peeling_decoder() missing 2 required positional arguments: 'edges_to_qubits' and 'num_qs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-135876af31e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorrection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpeeling_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merasure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merasure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: peeling_decoder() missing 2 required positional arguments: 'edges_to_qubits' and 'num_qs'"
     ]
    }
   ],
   "source": [
    "correction = peeling_decoder(erasure)\n",
    "print(erasure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'correction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8e8520085beb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'correction' is not defined"
     ]
    }
   ],
   "source": [
    "print(correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_decoder_graph(S):\n",
    "    n = len(S[0])\n",
    "    vertices = S\n",
    "    edges_by_qubit = {}\n",
    "    edges = []\n",
    "    for s1, s2 in itertools.combinations(S, 2):\n",
    "        for q in range(n):\n",
    "            if s1[q] =='1' and  s2[q]=='1':\n",
    "                if (s1, s2) in edges:\n",
    "                    edges_by_qubit[(s1,s2)].extend([q])\n",
    "                else:   \n",
    "                    edges_by_qubit[(s1,s2)]=[q]\n",
    "                    edges.append((s1,s2))\n",
    "    return((vertices, edges, edges_by_qubit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (1, 3), (2, 3)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = [1,2,3]\n",
    "list(itertools.combinations(example,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['101', '110', '011'],\n",
       " [('101', '110'), ('101', '011'), ('110', '011')],\n",
       " {('101', '110'): [0], ('101', '011'): [2], ('110', '011'): [1]})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_decoder_graph(['101','110','011'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexlist, edgelist, edges_by_qubit =make_decoder_graph(['111111111111110000000000000000000000000000', '000000011111111111111000000000000000000000', '000000000000001111111111111100000000000000', '000000000000000000000111111111111110000000', '000000000000000000000000000011111111111111'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('111111111111110000000000000000000000000000',\n",
       "  '000000011111111111111000000000000000000000'): [7, 8, 9, 10, 11, 12, 13],\n",
       " ('000000011111111111111000000000000000000000',\n",
       "  '000000000000001111111111111100000000000000'): [14, 15, 16, 17, 18, 19, 20],\n",
       " ('000000000000001111111111111100000000000000',\n",
       "  '000000000000000000000111111111111110000000'): [21, 22, 23, 24, 25, 26, 27],\n",
       " ('000000000000000000000111111111111110000000',\n",
       "  '000000000000000000000000000011111111111111'): [28, 29, 30, 31, 32, 33, 34]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_by_qubit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_graph = graph(vertexlist, edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "syndrome = {'111111111111110000000000000000000000000000':1, \n",
    "            '000000011111111111111000000000000000000000': 0, \n",
    "            '000000000000001111111111111100000000000000': 0, \n",
    "            '000000000000000000000111111111111110000000': 0, \n",
    "            '000000000000000000000000000011111111111111': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('111111111111110000000000000000000000000000', '000000011111111111111000000000000000000000'): 0, ('000000011111111111111000000000000000000000', '000000000000001111111111111100000000000000'): 0, ('000000000000001111111111111100000000000000', '000000000000000000000111111111111110000000'): 0, ('000000000000000000000111111111111110000000', '000000000000000000000000000011111111111111'): 0}\n",
      "[{'111111111111110000000000000000000000000000'}, {'000000011111111111111000000000000000000000'}, {'000000000000001111111111111100000000000000'}, {'000000000000000000000111111111111110000000'}, {'000000000000000000000000000011111111111111'}]\n",
      "[True, False, False, False, False]\n",
      "['111111111111110000000000000000000000000000']\n",
      "current L:  ['111111111111110000000000000000000000000000']\n",
      "fusion: []\n",
      "current L:  ['111111111111110000000000000000000000000000']\n",
      "fusion: [('111111111111110000000000000000000000000000', '000000011111111111111000000000000000000000')]\n",
      "<UnionFind:\n",
      "\telts=['111111111111110000000000000000000000000000', '000000011111111111111000000000000000000000', '000000000000001111111111111100000000000000', '000000000000000000000111111111111110000000', '000000000000000000000000000011111111111111'],\n",
      "\tsiz=[2, 1, 1, 1, 1],\n",
      "\tpar=[0, 0, 2, 3, 4],\n",
      "n_elts=5,n_comps=4>\n"
     ]
    }
   ],
   "source": [
    "new_erasure =construct_modified_erasure(decoder_graph, syndrome, [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('111111111111110000000000000000000000000000',\n",
       "  '000000011111111111111000000000000000000000')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_erasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qs = len(new_erasure[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'000000011111111111111000000000000000000000', '111111111111110000000000000000000000000000'}, {'000000011111111111111000000000000000000000', '000000000000001111111111111100000000000000'}]\n",
      "['111111111111110000000000000000000000000000', '000000000000001111111111111100000000000000']\n",
      "111111111111110000000000000000000000000000\n",
      "{'000000011111111111111000000000000000000000', '111111111111110000000000000000000000000000'}\n",
      "[{'000000011111111111111000000000000000000000', '000000000000001111111111111100000000000000'}]\n",
      "['000000000000001111111111111100000000000000', '000000011111111111111000000000000000000000']\n",
      "000000000000001111111111111100000000000000\n",
      "{'000000011111111111111000000000000000000000', '000000000000001111111111111100000000000000'}\n",
      "Z7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peeling_decoder(new_erasure, edges_by_qubit, num_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
